{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TITLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project Submission\n",
    "\n",
    "Please fill out:\n",
    "* __Student name:__ Cassarra Groesbeck\n",
    "* __Student pace:__ Part Time/ Flex\n",
    "* __Scheduled project review date/time:__ \n",
    "* __Instructor name:__ \n",
    "* __Blog post URL:__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction \n",
    "Every year, more than 795,000 people in the United States have a stroke. About 610,000 of these are first or new strokes. About 87% of all strokes are ischemic strokes, in which blood flow to the brain is blocked [CDC.gov](https://www.cdc.gov/stroke/facts.htm). Strokes are the No. 5 cause of death and a leading cause of disability in the United States. 80% of strokes are preventable [American Stoke Association](https://www.stroke.org/en/about-stroke). From 1990 to 2019, the change in the prevalence of stroke in the general population increased by about 60%. [newsroom.heart.org](https://newsroom.heart.org/news/u-s-stroke-rate-declining-in-adults-75-and-older-yet-rising-in-adults-49-and-younger)\n",
    "\n",
    "\n",
    "## 1a. Objectives\n",
    "Because of the nature of this problem, and in order to capture as many potential stroke victims as possible, I feel it is appropriate to be very aggressive with stroke predictions. For this reason I have chosen Recall as the evaluation metric for my models. This will inevitably lead to extra false positives, however, because of the health risks associated with strokes, I feel the measures needed to declare an individual to NOT be at risk, outweigh a misclassification of at risk.\n",
    "\n",
    "\n",
    "## 1b. Business Understanding\n",
    "Business that needs strokes predicted and why. (what are thay going to do with this information)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Understanding\n",
    "This dataset contains 5110 observations with 12 attributes (11 clinical features) for predicting stroke events. \n",
    "\n",
    "\n",
    "### 2a. Attribute Information\n",
    "| Column     | Description   |\n",
    "|------------|:--------------|\n",
    "| `id`               | **unique identifier**  |\n",
    "| `gender`           | **\"Male\", \"Female\" or \"Other\"**  |\n",
    "| `age`              | **age of the patient** |\n",
    "| `hypertension`     | **0 if the patient doesn't have hypertension, 1 if the patient has hypertension**  |\n",
    "| `heart_disease`    | **0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease**   |\n",
    "| `ever_married`     | **\"No\" or \"Yes\"**  |\n",
    "| `work_type`        | **\"children\", \"Govt_jov\", \"Never_worked\", \"Private\" or \"Self-employed\"**   |\n",
    "| `Residence_type`   | **\"Rural\" or \"Urban\"**  |\n",
    "| `avg_glucose_level`| **average glucose level in blood**  |\n",
    "| `bmi`              | **body mass index** |\n",
    "| `smoking_status`   | **\"formerly smoked\", \"never smoked\", \"smokes\" or \"Unknown\"***  |\n",
    "| `stroke`           | **1 if the patient had a stroke or 0 if not**  |\n",
    "|    **_*Note:_**      | _\"Unknown\" in_ `smoking_status` _means that the information is unavailable for this patient_ |\n",
    "\n",
    "\n",
    "### 2b. Acknowledgements\n",
    "Data comes from the [Stroke Prediction Dataset](https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset) and can be found on [kaggle](https://www.kaggle.com)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#plt.style.use('seaborn')\n",
    "sns.set_style('darkgrid', {'axes.facecolor': '0.9', \"grid.color\": \".6\", \"grid.linestyle\": \":\"})\n",
    "%matplotlib inline\n",
    "\n",
    "import xgboost\n",
    "\n",
    "from imblearn.over_sampling import SMOTEN, SMOTENC\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, \\\n",
    "ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer, KNNImputer\n",
    "from sklearn.pipeline import Pipeline#, FeatureUnion\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix,\\\n",
    "    precision_score, recall_score, accuracy_score, f1_score, log_loss,\\\n",
    "    roc_curve, roc_auc_score, classification_report, plot_roc_curve, auc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Exploring the Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a. Load and Visually Check the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/healthcare-dataset-stroke-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual check of raw df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. Drop Unnecessary `id` Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4c. Identify Target feature, `stroke`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'stroke'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4d. The Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4e. Exploring Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percent of missing data\n",
    "f'{(201/5110)*100:.3}%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just the nulls\n",
    "bmi_nulls = df[df['bmi'].isnull()]\n",
    "# `stroke` patients with missing `bmi` data\n",
    "bmi_nulls['stroke'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4f. Distribution of Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*30)\n",
    "print('Distribution of Target Feature')\n",
    "print('-'*30)\n",
    "print('COUNTS:')\n",
    "print(df[target].value_counts())\n",
    "print('- '*15)\n",
    "print('PERCENTAGES:')\n",
    "for value in [norm_value_count for norm_value_count \\\n",
    "                in enumerate(df[target].value_counts(normalize=True))]:\n",
    "    print(f'{value[0]}\\t{value[1]*100:.4}%')\n",
    "print(f'Name: {target}, dtype: int64') # just for symmetry\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show = df.drop(target, axis=1)\n",
    "\n",
    "print(\"-\"*30)\n",
    "print(f'Distribution of Other Features')\n",
    "print(\"-\"*30)\n",
    "for column in show.columns:\n",
    "    print(\"-\"*30)\n",
    "    print(f\"UNIQUE VALUES: {len(show[column].unique())}\")\n",
    "    if len(show[column].unique()) <= 5:\n",
    "        print(\"- \"*15)\n",
    "        print(show[column].value_counts())\n",
    "    else:\n",
    "        print(\"- \"*15)\n",
    "        print(f'\\t\\t  MIN: {show[column].min()}')\n",
    "        print(f'\\t\\t  MEAN: {round(show[column].mean())}')\n",
    "        print(f'\\t\\t  MAX: {show[column].max()}')\n",
    "        print((f'Name: {column}, dtype: float64')) \n",
    "    print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4g. Visualizing The of Distribution of Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "fig, axes = plt.subplots(ncols=4, nrows=3, figsize=(12, 10))\n",
    "fig.set_tight_layout(True)\n",
    "# plot\n",
    "for index, col in enumerate(df.columns):\n",
    "    ax = axes[index//4][index%4]\n",
    "    sns.histplot(data=df[col], ax=ax, linewidth=0.1, alpha=1)\n",
    "    ax.tick_params(axis='x', rotation=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES:\n",
    "\n",
    "- `gender`\n",
    " - There is only 1 'other' value, for simplicity I will drop this 1 row.\n",
    " - About 1000 more women than men in this dataset.\n",
    "- `age`\n",
    " - The youngest patient is under 1 yo. Oldest patient is 82.\n",
    " - Decent distribution, \n",
    " - Average age of patients in this dataset are 43 years old. \n",
    "- `hypertension`\n",
    " - Binary, 1 if the patient has hypertension.\n",
    " - Very similar distribution as target feature.\n",
    "- `heart_disease`\n",
    " - Binary, 1 if the patient has heart disease.\n",
    " - Almost identical distribution as target feature.\n",
    " - I am curious how `hypertension` & `heart_disease` will correlate with eachother. \n",
    "- `ever_married`\n",
    " - About 65/35 split with majority of patients listed as 'Yes.'\n",
    "- `work_type`\n",
    " - Only 5 categories. Not surprisingly, more than half answered 'Private.'\n",
    " - Other 4 make up little more than 40%.\n",
    " - 'Never_worked' is less than 1%.\n",
    "- `Residence_type`\n",
    " - Almost 50/50 split between 'Urban' and 'Rural.'\n",
    "- `avg_glucose_level` & `bmi` \n",
    " - continuous features that are both skewed positively.\n",
    " - `bmi` is missing 201 values (3.93%). Of those missing values, 40 are stroke patients.\n",
    "   - because of this missing data an imputer is required for modeling\n",
    "- `smoking_status`\n",
    " - about 30% of patients are listed as 'Unknown.'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4h. As indicated above in NOTES: Drop 1 'other' value in `gender`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop(df[df['gender']=='Other'].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Seperate and Split Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5a. Separate data into features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(target, axis = 1)\n",
    "y = data[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5b. Split data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    stratify=y, \n",
    "                                                    test_size=.2, \n",
    "                                                    random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Visualizing the `X_train` `y_train` data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6a. Make a visualization df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_df = pd.concat([X_train, y_train], axis=1)\n",
    "viz_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6b. Pair Plot\n",
    "I will start with a pair plot; this will help me visualize relationships between each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(viz_df, hue='stroke', markers=['*','<'], plot_kws={'linewidth':0.1});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES:\n",
    "`age` appears to be an important feature. \n",
    "\n",
    "The pair plot is great when comparing continuous features, however, it is useless when comparing two binary features, notice hypertension-heart_disease. Technically these features are categorical, with 1 and 0 representing \"Yes\" and \"No,\" so it is not surprising the pairplot does not reveal much about these features given they are masquerading around under the ruse of numeric values. On that same note, it is important to note, the pairplot excludes categorical features altogether. Notice `gender`, `ever_married`, `work_type`, `Residence_type`, and `smoking_status` are absent. These features will need to be explored seperately. But first, based on short comings of the pair plot, I would like to add a feature to better understanding the relationship between hypertension and heart_disease; I will call this new feature `hyper_heart`. Secondly, based on the insight of the pairplot, I want to add a feature that seperates out patients who are 50 and up. Next, I will break down `bmi` and `avg_glucose_level` into categorical ranges as this is more conducive to machine learning. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Adding Features\n",
    "Add features to `viz_df` (remember this is X_train and y_train concatenated) then explore the categorical features. \n",
    "- `age_50+`\n",
    " - The values in this column will be \n",
    "   - 1 : patients 50 and above\n",
    "   - 0 : patients 49 and below \n",
    "- `hyper_heart`\n",
    " - The values in this column will be \n",
    "   - 1 : patients with hypertension and heart disease \n",
    "   - 0 : if patients do not have BOTH hypertension and heart disease.\n",
    "- `bmi_range`\n",
    " - The values in this columns will be\n",
    "   - 'underweight' : patients with bmi < 18.49\n",
    "   - 'normal range' : patients with bmi between 18.5 and 24.9\n",
    "   - 'overweight' : patients with bmi between 25.0 and 29.9 \n",
    "   - 'obese' : patients with bmi 30 or greater\n",
    "  - Values for bmi ranges determined by - WHO classification of weight status - table found on the [National Library of Medicine](https://www.ncbi.nlm.nih.gov/books/NBK535456/figure/article-18425.image.f1/) website\n",
    "- `avg_glucose_range`\n",
    " - The values in this columns will depend on age\n",
    "   - for children < 5.99 (0-5 years old) :\n",
    "     - 'normal' : patients with average glucose level < 180\n",
    "     - 'action suggested' : if greater\n",
    "     - *note: I used 'action suggested' for children as I did not find much information on this age range and was uncomfortable labeling them 'diabetic' or 'pre-diabetic'*\n",
    "   - for children between 6 and 10 \n",
    "     - 'normal' : patients with average glucose level < 140 \n",
    "     - 'action suggested' : if greater\n",
    "   - for patients older than 10\n",
    "     - 'normal' : patients with average glucose level < 116.99\n",
    "     - 'prediabetic' : patients with average glucose level between 117 and 136.99\n",
    "     - 'diabetic' : if greater that 137\n",
    "  - Values for childrens ranges determined by [Nationwide Childrenâ€™s Hospital Diabetes Center Target Blood Glucose Ranges](https://www.nationwidechildrens.org/family-resources-education/health-wellness-and-safety-resources/resources-for-parents-and-kids/managing-your-diabetes/chapter-three-monitoring-blood-glucose)\n",
    "  - Values for adult ranges determined by [Medical News Today](https://www.medicalnewstoday.com/articles/a1c-chart-diabetes-numbers). This was the hardest as there is some discrepancy in these ranges. For example, the childrens table groups anyone from ten years and up as having a target range from 70 to 120, however the adult table labels 'normal' as anything below 117. I chose to use the data from these two tables despite this discrepancy becuase they are from credible resources. \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7a. Make copies\n",
    "Before I move forward I want to copy `X_train` and `X_test` in case I want as a reference later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_original = X_train.copy()\n",
    "X_test_original = X_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7b. Add Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [viz_df, X_train, X_test]  \n",
    "\n",
    "for df_to_add_to in dfs:\n",
    "    # print for reference\n",
    "    print(\"\\t\\t\\t\\t\\tBEFORE ADDING COLUMNS\")\n",
    "    print(df_to_add_to.shape)\n",
    "    display(df_to_add_to.head())\n",
    "    \n",
    "    # create lists for columns\n",
    "    hyper_heart_col = []\n",
    "    age_50_plus_col = []\n",
    "    bmi_ranges = []\n",
    "    avg_glucose_ranges = []\n",
    "    \n",
    "    for i in df_to_add_to.index:        \n",
    "        # Populate hyper_heart_col list\n",
    "        if (df_to_add_to['hypertension'][i]==1) and (df_to_add_to['heart_disease'][i]==1):\n",
    "            hyper_heart_col.append(1)\n",
    "        else:\n",
    "            hyper_heart_col.append(0)\n",
    "            \n",
    "        # Populate age_50_plus_col list\n",
    "        if df_to_add_to['age'][i] >= 50:\n",
    "            age_50_plus_col.append(1)\n",
    "        else:\n",
    "            age_50_plus_col.append(0)\n",
    "        \n",
    "        # Populate bmi_ranges list\n",
    "        if pd.isnull(df_to_add_to['bmi'][i]):\n",
    "            bmi_ranges.append(np.NaN)\n",
    "        elif (df_to_add_to['bmi'][i]<18.4):\n",
    "            bmi_ranges.append('underwieght')\n",
    "        elif (18.5 < df_to_add_to['bmi'][i] < 24.9):\n",
    "            bmi_ranges.append('normal range')\n",
    "        elif (25.0 < df_to_add_to['bmi'][i] < 29.9):\n",
    "            bmi_ranges.append('overweight')\n",
    "        else:\n",
    "            bmi_ranges.append('obese') \n",
    "        \n",
    "        # Populate avg_glucose_ranges list\n",
    "        if df_to_add_to['age'][i] < 6:\n",
    "            if df_to_add_to['avg_glucose_level'][i] < 180:\n",
    "                avg_glucose_ranges.append('normal')\n",
    "            else:\n",
    "                avg_glucose_ranges.append('action suggested')\n",
    "        elif 6 <= df_to_add_to['age'][i] < 10:\n",
    "            if df_to_add_to['avg_glucose_level'][i] < 140:\n",
    "                avg_glucose_ranges.append('normal')\n",
    "            else:\n",
    "                avg_glucose_ranges.append('action suggested')\n",
    "        else:\n",
    "            if df_to_add_to['avg_glucose_level'][i] < 117:\n",
    "                avg_glucose_ranges.append('normal')\n",
    "            elif 117 <= df_to_add_to['avg_glucose_level'][i] < 137:\n",
    "                avg_glucose_ranges.append('pre-diabetic')\n",
    "            else:\n",
    "                avg_glucose_ranges.append('diabetic')\n",
    "\n",
    "    # Add columns to dfs\n",
    "    df_to_add_to['hyper_heart'] = hyper_heart_col\n",
    "    df_to_add_to['age_50+'] = age_50_plus_col\n",
    "    df_to_add_to['bmi_range'] = bmi_ranges\n",
    "    df_to_add_to['avg_glucose_range'] = avg_glucose_ranges\n",
    "\n",
    "    print(\"\\t\\t\\t\\t\\tAFTER ADDING COLUMNS\")\n",
    "    print(df_to_add_to.shape)\n",
    "    display(df_to_add_to.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Visualizations of Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8a. Convert to Categorical \n",
    "Before I plot, I will convert those sneaky false numeric features into their true categorical form. This will make for better looking labels and visuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nums_to_cats = ['stroke', 'hypertension', 'heart_disease', 'hyper_heart', 'age_50+']\n",
    "for feat in nums_to_cats:\n",
    "    viz_df[feat] = viz_df[feat].map({1:'Yes', 0:'No'})\n",
    "    \n",
    "viz_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8b. Plotting the Distribution of Categorical Features from `viz_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set up plot\n",
    "fig, axes = plt.subplots(ncols=3, nrows=4, figsize=(15, 23))\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "# Lists for loops\n",
    "feats = ['gender',\n",
    "         'hypertension',\n",
    "         'heart_disease',\n",
    "         'ever_married',\n",
    "         'work_type',\n",
    "         'Residence_type',\n",
    "         'smoking_status', \n",
    "         'hyper_heart',\n",
    "         'age_50+', \n",
    "         'bmi_range', \n",
    "         'avg_glucose_range']\n",
    "\n",
    "titles = ['Sex',\n",
    "         'Hypertension',\n",
    "         'Heart Disease',\n",
    "         'Ever Married',\n",
    "         'Work Type',\n",
    "         'Residence Type',\n",
    "         'Smoking Status',\n",
    "         'Hypertention and Heart Disease', \n",
    "         '50 and above',\n",
    "         'BMI Ranges', \n",
    "         'Average Glucose Ranges']\n",
    "\n",
    "vals = ['No', 'Yes']\n",
    "\n",
    "labels = ['Non-Stroke','Stroke']\n",
    "\n",
    "\n",
    "for i in range(len(feats)):\n",
    "    # Set up plots\n",
    "    ax = axes[i//3][i%3]\n",
    "    ax.set(xlabel=titles[i], ylabel='Number of Patients')\n",
    "    \n",
    "    for index in range(2):\n",
    "        # Define the df \n",
    "        bar_df = viz_df[viz_df['stroke']==vals[index]]\n",
    "        count_df = pd.DataFrame(bar_df.groupby([feats[i]])[feats[i]].count())\n",
    "        plot_df = count_df.rename(columns={feats[i]: 'count'}).reset_index()\n",
    "\n",
    "        # Plot\n",
    "        ax.bar(plot_df[feats[i]], plot_df['count'], label=labels[index]) \n",
    "        ax.tick_params(axis='x', rotation=60)\n",
    "        ax.legend();\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES:\n",
    "The added feature `age_50+` further suggests that age is prehaps the most significant feature. Other important factors seems to be `bmi_range`, and `avg_glucose_range`. I am hesitant to label `ever_married` as significant simply becuase marriage coincides with age, but I am not ruling it insignificant either. `hypertension`, `heart_disease`, sex (`gender`), and potentially `smoking_status` also seem to play important roles in stokes. \n",
    "\n",
    "Of the added features I will keep:\n",
    "- `age_50+`\n",
    "- `bmi_range`\n",
    "- `avg_glucose_range`\n",
    "\n",
    "And drop: \n",
    "- `hyper_heart`\n",
    "\n",
    "I will also drop the 3 orignal continuous features:\n",
    "- `age`\n",
    "- `bmi`\n",
    "- `avg_glucose_level`\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Drop Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [X_train, X_test] \n",
    "\n",
    "feats_to_drop = ['age', 'bmi', 'avg_glucose_level', 'hyper_heart']\n",
    "\n",
    "for df_to_drop_from in dfs:    \n",
    "    # print for reference\n",
    "    print(\"\\t\\t\\t\\t\\tBEFORE DROPPING COLUMNS\")\n",
    "    print(df_to_drop_from.shape)\n",
    "    display(df_to_drop_from.head())\n",
    "    \n",
    "    # drop features \n",
    "    #df_to_drop_from = \n",
    "    df_to_drop_from.drop(feats_to_drop, axis=1, inplace=True)\n",
    "    \n",
    "    # reprint after drops\n",
    "    print(\"\\t\\t\\t\\t\\tAFTER DROPPING COLUMNS\")\n",
    "    print(df_to_drop_from.shape)\n",
    "    display(df_to_drop_from.head())  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Function: `check_model` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This function does all the heavy lifting for me. Not only can it establish baseline models but it can also handle gridsearch for me. It has the option to change out imputers and scalers. Using smote and scaleing are optional, as well as using test data. It has the ability to output classification reports, threshold tables, and a side by side plot of a confusion maxtrix and ROC curve. With each model check it prints out the details of the classifier, imputer, scaler (if used) and smote method (if used). And finally, it returns the .fit model so I can calculate and save scores to a df (vs reading classification report). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model(model,\n",
    "                X_train=X_train,\n",
    "                X_test=X_test,\n",
    "                y_train=y_train,\n",
    "                y_test=y_test, \n",
    "                random_state=seed, \n",
    "                imputer=None,\n",
    "                smote=None,             \n",
    "                scaler=None,\n",
    "                grid_search=False,\n",
    "                use_test_data=False, \n",
    "                print_model_details=False,\n",
    "                show_classification_report=False, \n",
    "                show_thresholds_table=False,  \n",
    "                show_plots=False,\n",
    "                display_labels=None):\n",
    "    \n",
    "    \"\"\"   \n",
    "    \n",
    "    Uses sklearn.pipeline.Pipeline, sklearn.compose.ColumnTransformer, & imblearn.pipeline.Pipeline \n",
    "    to scale, using any sklearn scaler (this step is optional), one hot encode, using \n",
    "    sklearn.preprocessing.OneHotEncoder, impute, using any sklearn imputer (this step is optional), \n",
    "    and smote (Synthetic Minority Over-sampling Technique), using any sklearn smote technique (this step \n",
    "    is optional), to transform the data. Then, either fit that pipeline-model or feed it into \n",
    "    sklearn.model_selection.GridSearchCV then fit the girdsearch-model. By defualt GridSearch is bypassed\n",
    "    with grid_search=False.\n",
    "    \n",
    "    \n",
    "    Output\n",
    "    ---------- \n",
    "    (optional) Print model details\n",
    "    (optional) Classification Report\n",
    "    (optional) Thresholds, FPRs, TPRs Stats Table with AUC score\n",
    "    (optional) Plots Confusion matrix and ROC curve\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    Trained model (model.fit(X_train, y_train))\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    " \n",
    "    model : supervised learning model to be evaluated. \n",
    "    \n",
    "    X_train : pandas data frame, default=X_train\n",
    "    \n",
    "    X_test : pandas data frame, default=X_test\n",
    "                \n",
    "    y_train : pandas series, default=y_train,\n",
    "                \n",
    "    y_test : pandas series, default=y_test\n",
    "    \n",
    "    pipe_grid_param_dict : dict or list of dictionaries\n",
    "        sklearn.model_selection.GridSearchCV parameter: \n",
    "            Dictionary with parameters names (`str`) as keys and lists of\n",
    "            parameter settings to try as values, or a list of such\n",
    "            dictionaries, in which case the grids spanned by each dictionary\n",
    "            in the list are explored. This enables searching over any sequence\n",
    "            of parameter settings.\n",
    "    \n",
    "    random_state : int or RandomState instance, default=42\n",
    "        Controls the shuffling applied to the data before applying the split.\n",
    "        Pass an int for reproducible output across multiple function calls.\n",
    "        \n",
    "    imputer : any sklearn imputer, default=None\n",
    "        Transformers for missing value imputation\n",
    "        NOTE: Because the data has NaN values, an sklearn imputer must be specified.\n",
    "    \n",
    "    smote : any sklearn smote technique, default=None\n",
    "        Synthetic Minority Over-sampling Technique\n",
    "    \n",
    "    scaler : any sklearn preprocessing scaler, default=None\n",
    "    \n",
    "    grid_search : False or dict or list of dictionaries, default=False\n",
    "        If not set to False, this should be a dict for GridSearchCV param_grid.\n",
    "            sklearn.model_selection.GridSearchCV parameter: \n",
    "                Dictionary with parameters names (`str`) as keys and lists of\n",
    "                parameter settings to try as values, or a list of such\n",
    "                dictionaries, in which case the grids spanned by each dictionary\n",
    "                in the list are explored. This enables searching over any sequence\n",
    "                of parameter settings.\n",
    "\n",
    "    use_test_data : boolean True or False, default=False\n",
    "        Determines the data used to asses model performance.\n",
    "        \n",
    "    print_model_details : boolean True or False, default=False\n",
    "        Determines if function prints details about classifier, imputer, scaler (if used),\n",
    "        and smote technique (if used).\n",
    "        Example: \n",
    "            LogisticRegression(random_state=42, C=1.0, fit_intercept=True, max_iter=100, solver='lbfgs')\n",
    "            KNNImputer()\n",
    "            StandardScaler()\n",
    "            SMOTENC(categorical_features=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], random_state=42)\n",
    "            \n",
    "    \n",
    "    show_thresholds_report : boolean True or False, default=False\n",
    "        Print table with AUC score, Thresholds, FPR's and TPR's\n",
    "    \n",
    "    show_plots : boolean True or False, default=False\n",
    "        Plots Confusion Matrix and ROC curve.\n",
    "    \n",
    "    display_labels : list or 'None', default=None\n",
    "        If the target is binary 0,1 the labels can be changed to more descriptive labels. \n",
    "        Example: ['Healthy', 'HeartDisease']\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    ######################################################################\n",
    "    # 1. TRANSFORM-DATA PIPELINE                                         #\n",
    "    ######################################################################   \n",
    "    \n",
    "    # Determine if df all categorical #TODO\n",
    "    \n",
    "    # 1a. Seperate by type of data\n",
    "    cat_col_names = []\n",
    "    for col in X_train.columns:\n",
    "        if (col in X_train.select_dtypes('object').columns) or (sorted(X_train[col].unique())==[0,1]):\n",
    "            cat_col_names.append(col)\n",
    "            \n",
    "    \n",
    "    X_train_cat = X_train[cat_col_names]\n",
    "    X_train_nums = X_train.drop(cat_col_names, axis=1)\n",
    "    \n",
    "    \n",
    "    #X_train_nums = X_train.select_dtypes('float64')\n",
    "    #X_train_cat = X_train.select_dtypes('object')\n",
    "\n",
    "\n",
    "    # 1b. Pipeline 1 (numerical data)\n",
    "    numerical_pipeline = Pipeline(steps=[\n",
    "        ('scaler', scaler)])\n",
    "    \n",
    "    \n",
    "    # 1c. Pipeline 2 (categorical data)  \n",
    "    categorical_pipeline = Pipeline(steps=[\n",
    "        ('ohe', OneHotEncoder(sparse=False, handle_unknown='ignore'))])\n",
    "\n",
    "\n",
    "    # 1d. Converge pipelines 1 & 2\n",
    "    trans = ColumnTransformer(transformers=[\n",
    "        ('numerical', numerical_pipeline, X_train_nums.columns),\n",
    "        ('categorical', categorical_pipeline, X_train_cat.columns)],\n",
    "                             remainder='passthrough')\n",
    "        \n",
    "    \n",
    "    # 1e. Model with converged pipeline\n",
    "    model_pipe = imbpipeline(steps=[\n",
    "        ('trans', trans),\n",
    "        ('imputer', imputer),\n",
    "        ('smote', smote),\n",
    "        ('model', model)])\n",
    "\n",
    "    \n",
    "    ######################################################################\n",
    "    # 2. GRID SEARCH PIPELINE                                            #\n",
    "    ######################################################################   \n",
    "    \n",
    "\n",
    "    # 2a. Determine if using gridsearch\n",
    "    if grid_search != False:\n",
    "        best_model = GridSearchCV(estimator=model_pipe, \n",
    "                           param_grid=grid_search, \n",
    "                           scoring='recall', \n",
    "                           cv=3)\n",
    "\n",
    "        \n",
    "        # fit the model to evaluate\n",
    "        fit_model = best_model.fit(X_train, y_train) \n",
    "    \n",
    "    # if no grid search then .fit converged pipeline\n",
    "    else: \n",
    "        fit_model = model_pipe.fit(X_train, y_train) \n",
    "   \n",
    "\n",
    "    ######################################################################\n",
    "    # 3. (Optional) PRINT MODEL DETAILS                                  #\n",
    "    ######################################################################\n",
    "\n",
    "    if print_model_details: \n",
    "        \n",
    "        # 3a. Determine if using GridSearch\n",
    "        if grid_search:\n",
    "\n",
    "            \"\"\"\n",
    "            # 3a-1. Use .best_params_ dict and reformat to print the same way \n",
    "                classifiers/scalers/imputers etc are instantiated.\n",
    "\n",
    "\n",
    "                Example: \n",
    "                ----------\n",
    "\n",
    "                   .best_params_ = {'model__criterion': 'gini', \n",
    "                                    'model__max_depth': 6, \n",
    "                                    'scaler__with_mean': True} \n",
    "\n",
    "                    prints as: \n",
    "                        DecisionTreeClassifier(criterion='gini', max_depth=6, ..., N-param=N-value) \n",
    "                        StandardScaler(with_mean=True)\n",
    "            \"\"\"  \n",
    "            kind_of_params = {}\n",
    "            for k,v in fit_model.best_params_.items():\n",
    "                key = k.split(\"__\")[0]\n",
    "                if key not in kind_of_params.keys():\n",
    "                    kind_of_params[key] = \"\" \n",
    "                if k.split(\"__\")[1] == 'solver':\n",
    "                    kind_of_params[key] += k.split(\"__\")[1]+\"='\"+str(v)+\"', \" # solver has qoutes around it\n",
    "                elif k.split(\"__\")[1] == 'criterion':\n",
    "                    kind_of_params[key] += k.split(\"__\")[1]+\"='\"+str(v)+\"', \" # criterion has qoutes around it\n",
    "                else: \n",
    "                    kind_of_params[key] += k.split(\"__\")[1]+\"=\"+str(v)+\", \" #<-- notice comma\n",
    "\n",
    "\n",
    "            # 3a-2. Remove extra comma at end of each dic value\n",
    "            for k, v in kind_of_params.items():\n",
    "                kind_of_params[k] = v[:-2]\n",
    "\n",
    "\n",
    "            # 3a-3. Print in copy paste format:\n",
    "            # Ex. DecisionTreeClassifier(criterion='gini', ..., paramN=value)\n",
    "            if 'model' in  kind_of_params.keys():\n",
    "                model_text = str(model).split(\")\")[0]+\", \"+kind_of_params['model']+\")\"\n",
    "                print(model_text) \n",
    "            else:\n",
    "                print(model) # otherwise, use what was fed into function\n",
    "\n",
    "\n",
    "            if 'imputer' in kind_of_params.keys():\n",
    "                imputer_text = str(imputer).split(\"()\")[0]+\"(\"+kind_of_params['imputer']+\")\"\n",
    "                print(imputer_text)\n",
    "            else:\n",
    "                print(imputer)\n",
    "\n",
    "\n",
    "            if scaler != None:\n",
    "                if 'scaler' in kind_of_params.keys():\n",
    "                    scaler_text = str(scaler).split(\"()\")[0]+\"(\"+kind_of_params['scaler']+\")\"\n",
    "                    print(scaler_text) \n",
    "                else:\n",
    "                    print(scaler)  \n",
    "\n",
    "\n",
    "            if smote != None:\n",
    "                if 'smote' in kind_of_params.keys():\n",
    "                    smote_text = str(smote).split(\")\")[0]+\", \"+kind_of_params['smote']+\")\"\n",
    "                    print(smote_text)\n",
    "                else:\n",
    "                    print(smote)\n",
    "\n",
    "        # 3b. If bypassing GridSearch             \n",
    "        else: \n",
    "\n",
    "            # 3b-1 Print what was fed into function, example: DecisionTreeClassifier()\n",
    "            # model & imputer are manditory\n",
    "            print(model)  \n",
    "            print(imputer)\n",
    "\n",
    "            # scaler and/or smote are optional (will not print if not used) \n",
    "            if scaler != None:  \n",
    "                print(scaler)\n",
    "            if smote != None:\n",
    "                print(smote)\n",
    "\n",
    "    # 3c. Print type of data used in model evaluation\n",
    "    if use_test_data:\n",
    "        data_used_text = \"Test\"\n",
    "    else:\n",
    "        data_used_text = \"Train\"\n",
    "\n",
    "\n",
    "    ######################################################################\n",
    "    # 4. (Optional) CLASSIFICATION REPORT                                #\n",
    "    ######################################################################\n",
    "\n",
    "    \n",
    "    # 4a. Assign variables based on data using for evaluation\n",
    "    if use_test_data:\n",
    "        X_true = X_test\n",
    "        y_true = y_test\n",
    "    else: \n",
    "        X_true = X_train\n",
    "        y_true = y_train\n",
    "        \n",
    "    \n",
    "    if show_classification_report:\n",
    "        # 4b. Make predictions and print report \n",
    "        y_preds = fit_model.predict(X_true)\n",
    "        cr = classification_report(y_true, y_preds, digits=4)\n",
    "        print()\n",
    "        print('-'*54)\n",
    "        print(f'\\t  CLASSIFICATION REPORT : {data_used_text} Data')\n",
    "        print('-'*54)\n",
    "        print(cr)\n",
    "        print('-'*54)\n",
    "        \n",
    "\n",
    "        \n",
    "    ######################################################################\n",
    "    # 5. (Optional) THRESHOLDS TABLE                                     #\n",
    "    ######################################################################   \n",
    "   \n",
    "\n",
    "    if show_thresholds_table:\n",
    "        # 5a. Calculate the probability scores\n",
    "        if ('LogisticReg' in str(model)):\n",
    "            y_score = fit_model.decision_function(X_true) \n",
    "            fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "        else:\n",
    "            y_score = fit_model.predict_proba(X_true)\n",
    "            fpr, tpr, thresholds = roc_curve(y_true, y_score[:,1]) # <-- probability of Class 1\n",
    "\n",
    "        # 5b. Format values and print\n",
    "        # To display as: THRESHOLD: value | FPR: percent%, TPR:percent%\n",
    "        thresh_fp_tp = list(zip(thresholds, fpr, tpr))\n",
    "        these_to_print = [f'THRESHOLD: {e[0]:.2f} | FPR: {e[1]:.2%}, TPR:{e[2]:.2%}' \\\n",
    "                          for e in thresh_fp_tp]        \n",
    "        auc_score = auc(fpr, tpr)\n",
    "        \n",
    "        print('-'*54)\n",
    "        print('\\t\\t  THRESHOLD STATS')\n",
    "        print('-'*54)\n",
    "        print(f'AUC: {auc_score}')\n",
    "        print('- '*23)\n",
    "        for element in these_to_print:\n",
    "            print(element)\n",
    "        print('-'*54)\n",
    "        \n",
    "\n",
    "    ######################################################################\n",
    "    # 6. (Optional) VISUALIZATIONS                                       #\n",
    "    ######################################################################\n",
    "    \n",
    "    \n",
    "    if show_plots: \n",
    "        # Figure set up\n",
    "        plt.style.use('fivethirtyeight')\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(13, 5))\n",
    "        fig.suptitle(f'Model Evaluated on {data_used_text} Data', color='tab:blue', size=14)\n",
    "        \n",
    "\n",
    "        # Left  \n",
    "        axes[0].set_title(\"Confusion Matrix\", size=15)  \n",
    "        axes[0].grid(False)\n",
    "        plot_confusion_matrix(fit_model, X_true, y_true, \n",
    "                              cmap=plt.cm.Blues, \n",
    "                              ax=axes[0], \n",
    "                              display_labels=display_labels,\n",
    "                              normalize='true')\n",
    "\n",
    "        # Right \n",
    "        axes[1].set_title(\"ROC Curve\", size=15)\n",
    "        plot_roc_curve(fit_model, X_true, y_true, ax=axes[1]);\n",
    "        \n",
    "    \n",
    "    return fit_model\n",
    "\n",
    "\n",
    "print(\"ran\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## don't delete yet TESTS FOR FUNCTION\n",
    "\n",
    "d_tree_dic = {'model__criterion': ['gini', 'entropy'],\n",
    " 'model__max_depth': [1, 2],\n",
    " 'model__min_samples_split': [2,10],\n",
    " 'model__min_samples_leaf': [1, 6]}\n",
    "\n",
    "\n",
    "\n",
    "zero = round(data[target].value_counts(normalize=True)[1],6)\n",
    "one = round(data[target].value_counts(normalize=True)[0],6)\n",
    "class_weight_dic={0:zero, 1: one}\n",
    "\n",
    " \n",
    "log_reg_dict = {'model__C' : [1.0, 1e12],\n",
    "                'model__fit_intercept' : [True, False],\n",
    "                'model__class_weight' : ['balanced', class_weight_dic],\n",
    "                'model__solver' : ['lbfgs','liblinear'],\n",
    "                'model__max_iter' : [100,500]}\n",
    "\n",
    "\n",
    "\n",
    "imputer = IterativeImputer(random_state=seed)\n",
    "\n",
    "# Categorical Column Names\n",
    "cat_col_names = []\n",
    "for col in X_train.columns:\n",
    "    if (col in X_train.select_dtypes('object').columns) or (sorted(X_train[col].unique())==[0,1]):\n",
    "        cat_col_names.append(col)\n",
    "\n",
    "# Convert to indices      \n",
    "cat_col_indices = [X_train.columns.get_loc(col) for col in cat_col_names]\n",
    "\n",
    "\n",
    "smote=SMOTENC(categorical_features=cat_col_indices, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = LogisticRegression(random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_model3 = check_model(model3, \n",
    "                          imputer=imputer, \n",
    "                          print_model_details=True,\n",
    "                          show_classification_report=True, \n",
    "                          show_plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod3_with_smotenc = check_model(model3, \n",
    "                                imputer=imputer, \n",
    "                                smote=smote, \n",
    "                                show_classification_report=True, \n",
    "                                show_plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod3_with_gs = check_model(model3, \n",
    "                           imputer=imputer, \n",
    "                           scaler=StandardScaler(),\n",
    "                           smote=smote,\n",
    "                           grid_search=log_reg_dict,\n",
    "                           print_model_details=True,\n",
    "                           show_classification_report=True,\n",
    "                           show_plots=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod3_with_gs_NOsmote = check_model(model3, \n",
    "                                   imputer=imputer, \n",
    "                                   #smote=smote,\n",
    "                                   grid_search=log_reg_dict,\n",
    "                                   show_classification_report=True,\n",
    "                                   show_plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model4 = LogisticRegression(random_state=42, \n",
    "                            C=1.0, \n",
    "                            class_weight={0: 0.048738, 1: 0.951262}, \n",
    "                            fit_intercept=True, \n",
    "                            max_iter=100, \n",
    "                            solver='lbfgs')\n",
    "\n",
    "mod4_with_gs_NOsmote = check_model(model4, \n",
    "                                   imputer=imputer, \n",
    "                                   smote=smote,\n",
    "                                   use_test_data=True,\n",
    "                                   show_classification_report=True,\n",
    "                                   show_plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Set up for modeling\n",
    "Below I will instantiate the classifiers, imputers, scaler, and smotenc I will loop through in step 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11a. Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(random_state=seed) #class_weight\n",
    "\n",
    "d_tree = DecisionTreeClassifier(random_state=seed) #class_weight\n",
    "\n",
    "XGB = XGBClassifier(random_state=seed)\n",
    "\n",
    "forest = RandomForestClassifier(random_state=seed) #class_weight\n",
    "\n",
    "bag_tree = BaggingClassifier(DecisionTreeClassifier(random_state=seed))\n",
    "\n",
    "abc = AdaBoostClassifier(random_state=seed)\n",
    "\n",
    "etr = ExtraTreesClassifier(random_state=seed)\n",
    "\n",
    "gbc = GradientBoostingClassifier(random_state=seed)\n",
    "\n",
    "xgboost_XGB = xgboost.XGBClassifier(random_state=seed, objective='binary:logistic')\n",
    "\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11b. Imputers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_imputer = IterativeImputer(random_state=seed)\n",
    "\n",
    "sim_immputer = SimpleImputer()\n",
    "\n",
    "knn_imputer =  KNNImputer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11c. Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11d. Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Column Names\n",
    "cat_col_names = []\n",
    "for col in X_train.columns:\n",
    "    if (col in X_train.select_dtypes('object').columns) or (sorted(X_train[col].unique())==[0,1]):\n",
    "        cat_col_names.append(col)\n",
    "\n",
    "# Convert to indices      \n",
    "cat_col_indices = [X_train.columns.get_loc(col) for col in cat_col_names]\n",
    "\n",
    "if len(cat_col_names) == len(X_train.columns):\n",
    "    smote = SMOTEN(random_state=seed)\n",
    "else:\n",
    "    smote = SMOTENC(categorical_features=cat_col_indices, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Modeling without GridSearchCV\n",
    "### Bypassing GridSearch for now.\n",
    "Using forloop to run baselines, scaled and non scaled (StandardScaler when scaled), smote and non smote (SMOTENC or SMOTEN depending on weather or not data is all categorical or not) and putting results in a `results` data frame. Some form of imputation is required due to NaNs in `bmi` or `bmi_ranges` so the loop runs through 3 different ways of imputing data (IterativeImputer, SimpleImputer, KNNImputer). Scaling and class imbalance techniques are optional so both have a None added to their list.  Note from step 8a, these models have no parameters yet other than setting a `random_state` (except in KNeighborsClassifier which does not have a `random_state` param)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12a. Create Lists for the Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = ['original', 'all_categorical', 'converted_cat']\n",
    "\n",
    "models = [log_reg,\n",
    "          d_tree,\n",
    "          XGB, \n",
    "          forest, \n",
    "          bag_tree, \n",
    "          abc, \n",
    "          etr, \n",
    "          gbc, \n",
    "          xgboost_XGB, \n",
    "          knn]\n",
    "\n",
    "model_names = ['LogisticRegression',\n",
    "               'DecisionTreeClassifier',\n",
    "               'XGBClassifier', \n",
    "               'RandomForestClassifier', \n",
    "               'BaggingClassifier', \n",
    "               'AdaBoostClassifier', \n",
    "               'ExtraTreesClassifier', \n",
    "               'GradientBoostingClassifier', \n",
    "               'xgboost.XGBClassifier', \n",
    "               'KNeighborsClassifier']\n",
    "\n",
    "imputers = [iter_imputer, \n",
    "            sim_immputer, \n",
    "            knn_imputer]\n",
    "\n",
    "imputer_names = ['IterativeImputer', \n",
    "                  'SimpleImputer', \n",
    "                  'KNNImputer']\n",
    "\n",
    "scalers = [None, scaler]\n",
    "\n",
    "scaler_names = ['None', 'StandardScaler']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12b. Create Empty `results` Data Frame to Store Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns = ['df_used', 'model', 'imputer', 'scaler', 'smote', \\\n",
    "                                  'train_recall', 'test_recall'])\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12c. Loop Through all Models, Imputers, Scaler, and Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_loops = 0\n",
    "\n",
    "# For each df\n",
    "for idex in dfs:\n",
    "    if idex == 'original':\n",
    "        use_this_X_train = X_train_original\n",
    "        use_this_X_test = X_test_original\n",
    "    else:\n",
    "        use_this_X_train = X_train\n",
    "        use_this_X_test = X_test\n",
    "\n",
    "        \n",
    "    ################################################################\n",
    "       \n",
    "    # Loop Through Models\n",
    "    for i in range(len(models)):\n",
    "        model = models[i]\n",
    "        model_name = model_names[i]\n",
    "        \n",
    "        num_of_loops += 1 \n",
    "        print(f'{num_of_loops} of 30 loops')\n",
    "\n",
    "        # Through Imputers\n",
    "        for ind in range(len(imputers)):\n",
    "            imputer = imputers[ind]\n",
    "            imputer_name = imputer_names[ind]\n",
    "\n",
    "            # With and Without Scaling\n",
    "            for index in range(2):\n",
    "                if (index == 1) & (idex != 'original'): # if all features categorical, skip scaling\n",
    "                    continue\n",
    "                else:\n",
    "                    scaler = scalers[index]\n",
    "                    scaler_name = scaler_names[index]\n",
    "\n",
    "                # With and Without using SMOTE\n",
    "                for smote_index in range(2):\n",
    "                    if smote_index == 0: # None\n",
    "                        class_imbal_option = None\n",
    "                        class_imbal_name = 'None'\n",
    "                    else:\n",
    "                        # Categorical Column Names\n",
    "                        cat_col_names = []\n",
    "                        for col in use_this_X_train.columns:\n",
    "                            if (col in use_this_X_train.select_dtypes('object').columns) \\\n",
    "                            or (sorted(use_this_X_train[col].unique())==[0,1]):\n",
    "                                cat_col_names.append(col)\n",
    "                                \n",
    "                        # if all categorical \n",
    "                        if len(cat_col_names) == len(use_this_X_train.columns):\n",
    "                            class_imbal_option = SMOTEN(random_state=seed)\n",
    "                            class_imbal_name = 'SMOTEN'\n",
    "                        else:\n",
    "                            # Convert cat_col_names to indices      \n",
    "                            cat_col_indices = [use_this_X_train.columns.get_loc(col) for col in cat_col_names]\n",
    "                            class_imbal_option = SMOTENC(categorical_features=cat_col_indices, \n",
    "                                                         random_state=seed)\n",
    "                            class_imbal_name = \"SMOTENC\"\n",
    "                            \n",
    "\n",
    "                    # Save Fitted Model\n",
    "                    fitted = check_model(model,\n",
    "                                         X_train=use_this_X_train,\n",
    "                                         X_test=use_this_X_test,\n",
    "                                         imputer=imputer, \n",
    "                                         scaler=scaler, \n",
    "                                         smote=class_imbal_option)\n",
    "\n",
    "                    # Calculate Train and Test Recall Score\n",
    "                    train_score = round(recall_score(y_train,fitted.predict(use_this_X_train)), 3)\n",
    "                    test_score = recall_score(y_test,fitted.predict(use_this_X_test))\n",
    "\n",
    "                    # Add to `results` df\n",
    "                    results.loc[len(results.index)] = [idex, model_name, imputer_name, scaler_name, \\\n",
    "                                                       class_imbal_name, train_score, test_score] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12c. View the Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# each model ranked\n",
    "for model in model_names:\n",
    "    display(results[results['model']==model].sort_values(['test_recall', 'train_recall'], ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bests = pd.DataFrame(columns = ['df_used', 'model', 'imputer', 'scaler', 'smote', \\\n",
    "                                  'train_recall', 'test_recall'])\n",
    "for model in model_names:\n",
    "    model_best = results[results['model']==model]\\\n",
    "    .sort_values(['test_recall', 'train_recall'], ascending=False)[:1]\n",
    "    bests = pd.concat([bests,model_best])\n",
    "\n",
    "bests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12d. Just the Baselines (no scaling or smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines = results[(results['scaler']=='None')&(results['smote']=='None')]\n",
    "baselines = baselines.sort_values(['test_recall', 'train_recall'], ascending=False)\n",
    "baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTES:** Not surprising there is a lot of over fitting. This is why GridSearchCV is so important. A note about the baseline imputers: there is not a single imputer that consistantly outperformed the others. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12e. Top Performers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(['test_recall', 'train_recall'], ascending=False)[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES:\n",
    "Top 5 performers witout parameter tweaking are:\n",
    "1. LogisticRegression\n",
    "2. AdaBoostClassifier\n",
    "3. GradientBoostingClassifier\n",
    "4. KNeighborsClassifier\n",
    "5. DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. Use GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### something important to say"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Final Model\n",
    "why this final model? What is so great about it. how does it solve business problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
